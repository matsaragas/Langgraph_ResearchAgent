{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9087742f-ed8c-401e-98c4-39cceccfca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5e770-1eaa-478d-8bcd-fdc660c4d0a4",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "\n",
    "Load a collection AI research arxiv papers from hugging face. The papers have been chunked and information (chunk id with arxiv id, paper title, chunk text, post chunk id and arxiv id from reference papaer) from each chunk is provided in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d35e5bc-c9a3-42c2-bfe3-7ae375440026",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"jamescalam/ai-arxiv2-semantic-chunks\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33d8b1-c49b-4737-b026-aeeb56e2aa3a",
   "metadata": {},
   "source": [
    "### Semantic Router\n",
    "\n",
    "Semantic Router is a superfast decision-making layer for your LLMs and agents. \n",
    "\n",
    "https://github.com/aurelio-labs/semantic-router\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accd3578-4c70-450f-9bce-323a748b00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from settings import config\n",
    "pinecone_api_key = config[\"pinecone_api_key\"]\n",
    "serpapi_key=config[\"serpapi_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d8843c-4507-43f9-be78-bc82c7fc35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904e1c9a-c253-41fb-b02e-609e85466d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OpenAIEncoder(name=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b6e196-f378-43f9-b13d-8cf4b57550a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada05587-2783-4a74-a01f-0b737657533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da970a5c-e856-4f9d-9423-925fabeb9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dca5088d-fa27-466f-9bb2-87c696d39b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"gpt-4o-research-agent\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # if it doesn't exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536, # the length of the vector generated by the encoder above. \n",
    "        metric='dotproduct',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initiated\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ff32e8f-dc93-4f66-a66a-90ef65d5d2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 1000}},\n",
       " 'total_vector_count': 1000}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ca3f99-1b49-405d-8544-6228615342c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07053473-552f-46a2-9af5-f6bc4a303c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.to_pandas().iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd51d110-69c8-4af5-9468-f22970352349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1905.07830']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['references'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46320a68-9acc-4050-a610-d9756094689f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b66339c3b2a49f69d787b325deafbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    batch = data[i:i_end].to_dict(orient=\"records\")\n",
    "    #get batch data\n",
    "    metadata = [{\n",
    "        \"title\": r[\"title\"],\n",
    "        \"content\": r[\"content\"],\n",
    "        \"arxiv_id\": r[\"arxiv_id\"],\n",
    "        \"references\": list(r[\"references\"])\n",
    "    } for r in batch]\n",
    "    # generate unique ids for each chunk\n",
    "    ids = [r[\"id\"] for r in batch]\n",
    "    content = [r[\"content\"] for r in batch]\n",
    "    #embed text\n",
    "    embeds = encoder(content)\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ddef0aa-0848-42f9-828f-63f1a9317525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "arxiv_id = \"2401.04088\"\n",
    "res = requests.get(f\"https://export.arxiv.org/abs/{arxiv_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65157480-2dc4-4cb4-834f-bf1d883ee49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model fine-tuned to follow instructions, Mixtral 8x7B - Instruct, that surpasses GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "abstract_pattern = re.compile(\n",
    "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "re_match = abstract_pattern.search(res.text)\n",
    "\n",
    "print(re_match.group(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33f8e71a-7413-4bcc-9376-56262e702942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coffee\n",
      "Coffee is a beverage brewed from roasted, ground coffee beans. Darkly colored, bitter, and slightly acidic, coffee has a stimulating effect on humans\n",
      "https://en.wikipedia.org/wiki/Coffee\n",
      "---\n",
      "Starbucks Coffee Company\n",
      "More than just great coffee. Explore the menu, sign up for Starbucks® Rewards, manage your gift card and more.\n",
      "https://www.starbucks.com/\n",
      "---\n",
      "r/Coffee\n",
      "thread where you can share what you are brewing or ask for bean recommendations. This is a place to share and talk about your favorite coffee roasters or beans.\n",
      "https://www.reddit.com/r/Coffee/\n",
      "---\n",
      "Coffee\n",
      "Shop Dunkin'® coffee, Folgers® coffee, Café Bustelo® coffee, and more. No matter how you like your coffee, we've got you covered! Choose from subtle to bold ...\n",
      "https://shop.smucker.com/collections/coffee?srsltid=AfmBOor5gqPO7OO9zc7mlXq6vddgEaioHlD9fp3TExGhPxKExpjsYFxq\n",
      "---\n",
      "Catalina Coffee: Order Online - Houston\n",
      "Catalina Coffee 2201 Washington Ave Houston, Texas 77007 (713) 861-8448 info@catalinacoffeeshop.com Get directions\n",
      "https://www.catalinacoffeeshop.com/\n",
      "---\n",
      "Coffee - The Nutrition Source - Harvard University\n",
      "A plain “black” cup of coffee is a very low calorie drink—8 ounces only contains 2 calories! However, adding sugar, cream, and milk can quickly bump up the ...\n",
      "https://nutritionsource.hsph.harvard.edu/food-features/coffee/\n",
      "---\n",
      "Buy Coffee, Tea, Powders Online | The Coffee Bean & Tea ...\n",
      "Every Tastemaker has a story. · Great coffee starts with the hands that brew it. · Try one of our delicious NEW Organic L.A Series coffees · & get FREE SHIPPING ...\n",
      "https://www.coffeebean.com/\n",
      "---\n",
      "9 Reasons Why (the Right Amount of) Coffee Is Good for You\n",
      "Coffee is chock full of substances that may help guard against conditions more common in women, including Alzheimer's disease and heart disease.\n",
      "https://www.hopkinsmedicine.org/health/wellness-and-prevention/9-reasons-why-the-right-amount-of-coffee-is-good-for-you\n",
      "---\n",
      "Scooter's Coffee | Be Amazing\n",
      "Wake up to the ahhh-mazing aroma of quality. Subscribe to Scooter's Coffee® delivery and enjoy 100% Arabica beans, sourced directly from farmers.\n",
      "https://www.scooterscoffee.com/\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "# https://serpapi.com/manage-api-key\n",
    "serpapi_params = {\n",
    "    \"engine\": \"google\",\n",
    "    \"api_key\": serpapi_key\n",
    "}\n",
    "\n",
    "search = GoogleSearch({\n",
    "    **serpapi_params,\n",
    "    \"q\": \"coffee\"\n",
    "})\n",
    "\n",
    "results = search.get_dict()[\"organic_results\"]\n",
    "contexts = \"\\n---\\n\".join(\n",
    "    [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results]\n",
    ")\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2934635-4cd8-4458-ba3a-8c8f0b7aeff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
